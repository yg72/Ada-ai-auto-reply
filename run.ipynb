{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Read JSON data from ./input/categories.json\n",
      "INFO:root:Read JSON data from ./input/categories.json\n",
      "INFO:root:Read JSON data from ./input/categories.json\n",
      "INFO:root:Read JSON data from ./input/categories.json\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from rexpand_pyutils_file import write_file\n",
    "from utils.conversation_data import load_conversation_data\n",
    "from utils.json import to_json_compatible\n",
    "from models.context import Context,ConversationMessage\n",
    "from nodes.orchestrator import orchestrate\n",
    "from models.workflow import State\n",
    "import json\n",
    "from nodes.orchestrator_langgraph import orchestrate as orchestrate_langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON conversations from file\n",
    "with open('./input/test1_conversation.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "messages_test = [\n",
    "    ConversationMessage(\n",
    "        id=item['id'],\n",
    "        role=item['role'],\n",
    "        name=item.get('name', ''),\n",
    "        body_text=item['body_text'],\n",
    "        attachments_text=item['attachments_text'],\n",
    "        delivered_at=item['delivered_at']\n",
    "    )\n",
    "    for item in data\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Wrote JSON data to ./output/current_messages.json\n"
     ]
    }
   ],
   "source": [
    "# Select a conversation to process\n",
    "messages_end = 2\n",
    "messages = messages_test[:messages_end]\n",
    "context = Context(messages=messages)\n",
    "write_file('./output/current_messages.json', to_json_compatible(messages))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop with Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step': 'todo: human action required', 'context': Context(messages=[ConversationMessage(id='06aebc21-ed8c-4c8e-89c0-35dabb049025', role='job seeker', name='Mingzhi Li', body_text=\"Hi Niraj,\\nI'm Mingzhi. I'm eager to explore the new Software Developer opening at Oracle. Could we connect for more info or a referral?\\nKind regards,\\nMingzhi.\", attachments_text='', delivered_at=1741098268349), ConversationMessage(id='56c4d155-5b08-4758-b44c-f5fe648bf4e1', role='referrer', name='Niraj P.', body_text=\"Hi, Mingzhi,\\nSure, we can connect. \\nPlease share your resume and we'll start from there. \\nRegards\\nNiraj\", attachments_text='', delivered_at=1741098324075)], user_profile=None, referrer_profile=None), 'classified_category': ClassifierResult(category='agree_on_condition', confidence=0.95, reason='The referrer, Niraj, explicitly agrees to connect but requests the job seeker to share their resume first, indicating a conditional agreement to help.', referenced_message_ids=['56c4d155-5b08-4758-b44c-f5fe648bf4e1']), 'summarized_actions': ActionSummarizerResult(actions=[Action(action='Provide the latest resume', confidence=0.95, reason='The referrer, Niraj, has agreed to connect but requested the job seeker to share their resume first to proceed further.')]), 'auto_assign_actions': False, 'auto_assign_topics': False}\n"
     ]
    }
   ],
   "source": [
    "# Fresh start. In this case, no human in the loop with topics suggested\n",
    "state = State(context=context, auto_assign_actions=False, auto_assign_topics=False)\n",
    "app = orchestrate_langgraph(state)\n",
    "print(app.invoke(state))\n",
    "# for output in app.stream(state):\n",
    "#     # stream() yields dictionaries with output keyed by node name\n",
    "#     for key, value in output.items():\n",
    "#         print(f\"Output from node '{key}':\")\n",
    "#         print(\"---\")\n",
    "#         print(value)\n",
    "#     print(\"\\n---\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop with business logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next: select topics\n",
      "ClassifierResult(category='agree_on_condition', confidence=0.95, reason='The referrer, Niraj, agrees to connect but requests the job seeker to share their resume first, indicating a conditional agreement to help.', referenced_message_ids=['56c4d155-5b08-4758-b44c-f5fe648bf4e1'])\n",
      "ActionSummarizerResult(actions=[Action(action='Provide the latest resume to Niraj P.', confidence=0.95, reason='Niraj agreed to connect and requested the resume to proceed further.')])\n",
      "ActionSummarizerResult(actions=[Action(action='Provide the latest resume to Niraj P.', confidence=0.95, reason='Niraj agreed to connect and requested the resume to proceed further.')])\n",
      "InferenceResult(inferences=[Inference(inference=True, confidence=0.9, reason=\"The referrer, Niraj, responded positively to the job seeker's request by agreeing to connect and asking for the resume to start the referral process. This indicates a willingness to refer, contingent on receiving the resume.\")])\n",
      "TopicSuggesterResult(topics=[Topic(topic='Thank you', confidence=0.95, reason=\"The referrer agreed to connect and requested the resume, so it's polite to thank them for their willingness to help.\"), Topic(topic='Share resume', confidence=0.98, reason='The referrer specifically asked for the resume to start the referral process, so sharing the resume is the next logical step.'), Topic(topic='Express eagerness to connect', confidence=0.9, reason='The referrer agreed to connect, so expressing eagerness to discuss further would keep the conversation positive and proactive.')])\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Fresh start. In this case, no human in the loop with topics suggested\n",
    "state = State(context=context, auto_assign_actions=False, auto_assign_topics=False)\n",
    "state = orchestrate(state)\n",
    "\n",
    "print(state.step)\n",
    "print(state.classified_category)\n",
    "print(state.summarized_actions)\n",
    "print(state.fulfilled_actions)  # This is the selected actions after summarization\n",
    "print(state.inferred_results)\n",
    "print(state.suggested_topics)\n",
    "print(state.selected_topics)\n",
    "print(state.generated_reply_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
